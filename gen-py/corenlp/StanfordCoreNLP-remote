#!/usr/bin/env python
#
# Autogenerated by Thrift Compiler (0.9.0)
#
# DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
#
#  options string: py:utf8strings,slots,new_style
#

import sys
import pprint
from urlparse import urlparse
from thrift.transport import TTransport
from thrift.transport import TSocket
from thrift.transport import THttpClient
from thrift.protocol import TBinaryProtocol

import StanfordCoreNLP
from ttypes import *

if len(sys.argv) <= 1 or sys.argv[1] == '--help':
  print ''
  print 'Usage: ' + sys.argv[0] + ' [-h host[:port]] [-u url] [-f[ramed]] function [arg1 [arg2...]]'
  print ''
  print 'Functions:'
  print '  void ping()'
  print '  void zip()'
  print '   parse_text(string text,  outputFormat)'
  print '  ParseTree parse_tokens( tokens,  outputFormat)'
  print '  ParseTree parse_tagged_sentence(string taggedSentence,  outputFormat, string divider)'
  print '  string lexicalize_parse_tree(string tree)'
  print '   get_entities_from_text(string text)'
  print '   get_entities_from_tokens( tokens)'
  print '   get_entities_from_trees( trees)'
  print '   resolve_coreferences_in_text(string text)'
  print '   resolve_coreferences_in_tokenized_sentences( sentencesWithTokensSeparatedBySpace)'
  print '   resolve_coreferences_in_trees( trees)'
  print '   evaluate_tregex_pattern(string parseTree, string tregexPattern)'
  print '   tag_text(string untokenizedText)'
  print '   tag_tokenized_sentence( tokenizedSentence)'
  print '  string untokenize_sentence( sentenceTokens)'
  print '   tokenize_text(string arbitraryText)'
  print '  ParseTree sr_parse_tagged_sentence(string taggedSentence,  outputFormat, string divider)'
  print '   sr_parse_text(string untokenizedText,  outputFormat)'
  print '  ParseTree sr_parse_tokens( tokenizedSentence,  outputFormat)'
  print ''
  sys.exit(0)

pp = pprint.PrettyPrinter(indent = 2)
host = 'localhost'
port = 9090
uri = ''
framed = False
http = False
argi = 1

if sys.argv[argi] == '-h':
  parts = sys.argv[argi+1].split(':')
  host = parts[0]
  if len(parts) > 1:
    port = int(parts[1])
  argi += 2

if sys.argv[argi] == '-u':
  url = urlparse(sys.argv[argi+1])
  parts = url[1].split(':')
  host = parts[0]
  if len(parts) > 1:
    port = int(parts[1])
  else:
    port = 80
  uri = url[2]
  if url[4]:
    uri += '?%s' % url[4]
  http = True
  argi += 2

if sys.argv[argi] == '-f' or sys.argv[argi] == '-framed':
  framed = True
  argi += 1

cmd = sys.argv[argi]
args = sys.argv[argi+1:]

if http:
  transport = THttpClient.THttpClient(host, port, uri)
else:
  socket = TSocket.TSocket(host, port)
  if framed:
    transport = TTransport.TFramedTransport(socket)
  else:
    transport = TTransport.TBufferedTransport(socket)
protocol = TBinaryProtocol.TBinaryProtocol(transport)
client = StanfordCoreNLP.Client(protocol)
transport.open()

if cmd == 'ping':
  if len(args) != 0:
    print 'ping requires 0 args'
    sys.exit(1)
  pp.pprint(client.ping())

elif cmd == 'zip':
  if len(args) != 0:
    print 'zip requires 0 args'
    sys.exit(1)
  pp.pprint(client.zip())

elif cmd == 'parse_text':
  if len(args) != 2:
    print 'parse_text requires 2 args'
    sys.exit(1)
  pp.pprint(client.parse_text(args[0],eval(args[1]),))

elif cmd == 'parse_tokens':
  if len(args) != 2:
    print 'parse_tokens requires 2 args'
    sys.exit(1)
  pp.pprint(client.parse_tokens(eval(args[0]),eval(args[1]),))

elif cmd == 'parse_tagged_sentence':
  if len(args) != 3:
    print 'parse_tagged_sentence requires 3 args'
    sys.exit(1)
  pp.pprint(client.parse_tagged_sentence(args[0],eval(args[1]),args[2],))

elif cmd == 'lexicalize_parse_tree':
  if len(args) != 1:
    print 'lexicalize_parse_tree requires 1 args'
    sys.exit(1)
  pp.pprint(client.lexicalize_parse_tree(args[0],))

elif cmd == 'get_entities_from_text':
  if len(args) != 1:
    print 'get_entities_from_text requires 1 args'
    sys.exit(1)
  pp.pprint(client.get_entities_from_text(args[0],))

elif cmd == 'get_entities_from_tokens':
  if len(args) != 1:
    print 'get_entities_from_tokens requires 1 args'
    sys.exit(1)
  pp.pprint(client.get_entities_from_tokens(eval(args[0]),))

elif cmd == 'get_entities_from_trees':
  if len(args) != 1:
    print 'get_entities_from_trees requires 1 args'
    sys.exit(1)
  pp.pprint(client.get_entities_from_trees(eval(args[0]),))

elif cmd == 'resolve_coreferences_in_text':
  if len(args) != 1:
    print 'resolve_coreferences_in_text requires 1 args'
    sys.exit(1)
  pp.pprint(client.resolve_coreferences_in_text(args[0],))

elif cmd == 'resolve_coreferences_in_tokenized_sentences':
  if len(args) != 1:
    print 'resolve_coreferences_in_tokenized_sentences requires 1 args'
    sys.exit(1)
  pp.pprint(client.resolve_coreferences_in_tokenized_sentences(eval(args[0]),))

elif cmd == 'resolve_coreferences_in_trees':
  if len(args) != 1:
    print 'resolve_coreferences_in_trees requires 1 args'
    sys.exit(1)
  pp.pprint(client.resolve_coreferences_in_trees(eval(args[0]),))

elif cmd == 'evaluate_tregex_pattern':
  if len(args) != 2:
    print 'evaluate_tregex_pattern requires 2 args'
    sys.exit(1)
  pp.pprint(client.evaluate_tregex_pattern(args[0],args[1],))

elif cmd == 'tag_text':
  if len(args) != 1:
    print 'tag_text requires 1 args'
    sys.exit(1)
  pp.pprint(client.tag_text(args[0],))

elif cmd == 'tag_tokenized_sentence':
  if len(args) != 1:
    print 'tag_tokenized_sentence requires 1 args'
    sys.exit(1)
  pp.pprint(client.tag_tokenized_sentence(eval(args[0]),))

elif cmd == 'untokenize_sentence':
  if len(args) != 1:
    print 'untokenize_sentence requires 1 args'
    sys.exit(1)
  pp.pprint(client.untokenize_sentence(eval(args[0]),))

elif cmd == 'tokenize_text':
  if len(args) != 1:
    print 'tokenize_text requires 1 args'
    sys.exit(1)
  pp.pprint(client.tokenize_text(args[0],))

elif cmd == 'sr_parse_tagged_sentence':
  if len(args) != 3:
    print 'sr_parse_tagged_sentence requires 3 args'
    sys.exit(1)
  pp.pprint(client.sr_parse_tagged_sentence(args[0],eval(args[1]),args[2],))

elif cmd == 'sr_parse_text':
  if len(args) != 2:
    print 'sr_parse_text requires 2 args'
    sys.exit(1)
  pp.pprint(client.sr_parse_text(args[0],eval(args[1]),))

elif cmd == 'sr_parse_tokens':
  if len(args) != 2:
    print 'sr_parse_tokens requires 2 args'
    sys.exit(1)
  pp.pprint(client.sr_parse_tokens(eval(args[0]),eval(args[1]),))

else:
  print 'Unrecognized method %s' % cmd
  sys.exit(1)

transport.close()
